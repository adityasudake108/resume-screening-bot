import nltk

# Download correct resources
nltk.download('punkt')
nltk.download('stopwords')
# Add punkt_tab resource to fix the tokenization error
nltk.download('punkt_tab')
